# -*- coding: utf-8 -*-
"""Copy of Forex Currency Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CKAtjB3rtEWJvp6CANYkQ1ByUcBtPtZc
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#loading data
data = pd.read_csv("sample_data/Foreign_Exchange_Rates.xls")
#drop Nan columns
data.dropna(axis=1, how='all', inplace=True)
data.drop('Unnamed: 0', axis=1, inplace=True)
data.head()

print(data.dtypes)

#convert to float
exclude = 'Time Serie'
to_convert = [c for c in data.columns if c != exclude]
data[to_convert] = data[to_convert].replace('ND', np.nan)
data[to_convert] = data[to_convert].astype(float)

data['Time Serie'] = pd.to_datetime(data['Time Serie'], format='%d-%m-%Y')

data.isnull().sum()

data.fillna(method='ffill', inplace=True)

data.describe()

import math
data.set_index('Time Serie', inplace=True)

# 3) إعداد شبكة subplots تلقائيّة
n = len(data.columns)          # عدد العملات
ncols = 2                      # نرسم عمودين في كل صف
nrows = math.ceil(n / ncols)   # عدد الصفوف اللازم

fig, axes = plt.subplots(
    nrows, ncols,
    figsize=(14, 3 * nrows),
    sharex=True
)
axes = axes.flatten()

# 4) للرسم: كل عملة في محورها الخاص
for ax, col in zip(axes, data.columns):
    ax.plot(data.index, data[col], linewidth=1)
    ax.set_title(col, fontsize=10)
    ax.set_ylabel('Rate')
    ax.grid(True)

# 5) إخفاء أي محاور زائدة (لو كان عدد العملات فردي)
for ax in axes[n:]:
    ax.set_visible(False)

plt.tight_layout()
plt.show()

corr = data.corr()
mask = np.triu(np.ones_like(corr, dtype=bool))

# 4) رسم Heatmap محسّن
plt.figure(figsize=(12, 10))
sns.heatmap(
    corr,
    mask=mask,
    annot=True,           # عرض الأرقام داخل الخلايا
    fmt=".2f",            # دقتان عشريتان
    cmap="coolwarm",
    linewidths=0.5,       # فواصل بيضاء بين الخلايا
    cbar_kws={"shrink": 0.6},  # تصغير شريط الألوان
    annot_kws={"fontsize": 8}  # حجم خط الأرقام
)

# 5) ضبط تسميات المحاور
plt.xticks(rotation=45, ha='right', fontsize=9)
plt.yticks(rotation=0, fontsize=9)

plt.title("Correlation Matrix of Daily Returns", pad=20, fontsize=14)
plt.tight_layout()
plt.show()

"""1. Baseline Model:
A naive model that predicts the next value as the last observed value in the training set. It is used as a benchmark to compare the performance of more advanced models.

2. ARIMA:
A classical statistical model that uses past values and errors to forecast future values. It works best with stationary time series data and is good for capturing short-term dependencies.

3. Prophet:
A forecasting tool developed by Facebook, designed for time series with strong trends and seasonality. It is user-friendly and automatically models holidays and yearly/weekly seasonality.

4. XGBoost:
A machine learning model based on boosted decision trees. For time series, it requires creating lag features manually. It is powerful for complex data and when you want to include additional features.

5. LSTM:
A type of recurrent neural network designed for sequential data. It can learn long-term dependencies and complex patterns, making it suitable for difficult and non-linear time series problems.


"""

import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

def prepare_lstm_data(series, n_steps):
    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(series.values.reshape(-1, 1))
    X, y = [], []
    for i in range(n_steps, len(scaled)):
        X.append(scaled[i - n_steps:i, 0])
        y.append(scaled[i, 0])
    X, y = np.array(X), np.array(y)
    X = X.reshape((X.shape[0], X.shape[1], 1))  # (samples, timesteps, features)
    return X, y, scaler

def lstm_predict(train, test, n_steps=7, epochs=10):
    X_train, y_train, scaler = prepare_lstm_data(train, n_steps)
    model = Sequential([
         LSTM(64, activation='relu', return_sequences=True, input_shape=(n_steps, 1)),  # الطبقة الأولى
         LSTM(32, activation='relu', return_sequences=True),                           # الطبقة الثانية
         LSTM(16, activation='relu'),                                                  # الطبقة الثالثة (بدون return_sequences)
         Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(X_train, y_train, epochs=epochs, verbose=0)

    # التنبؤ خطوة بخطوة على test
    history = train[-n_steps:].tolist()
    preds = []
    for t in range(len(test)):
        x_input = np.array(history[-n_steps:]).reshape((1, n_steps, 1))
        x_scaled = scaler.transform(np.array(history[-n_steps:]).reshape(-1,1)).reshape(1, n_steps, 1)
        yhat_scaled = model.predict(x_scaled, verbose=0)
        yhat = scaler.inverse_transform(yhat_scaled.reshape(-1,1))[0,0]
        preds.append(yhat)
        history.append(yhat)
    return np.array(preds)

import pandas as pd
import numpy as np
import os
import re
from sklearn.metrics import mean_absolute_error, mean_squared_error
from prophet import Prophet
from statsmodels.tsa.arima.model import ARIMA
import xgboost as xgb
import joblib
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

def mape(y_true, y_pred):
    return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-9))) * 100

def clean_filename(s):
    return re.sub(r'[^A-Za-z0-9]+', '_', s)

os.makedirs("models", exist_ok=True)
results = []
lags = 7  # عدد الأيام السابقة كـ features

for col in data.columns:
    ts = data[col].dropna()
    ts.index = pd.to_datetime(ts.index)
    train = ts.iloc[:-60]
    test = ts.iloc[-60:]
    res = {"Currency": col}

    # ========== Baseline ==========
    y_pred_baseline = pd.Series(train.iloc[-1], index=test.index)
    res['Baseline RMSE'] = np.sqrt(mean_squared_error(test, y_pred_baseline))
    res['Baseline MAE']  = mean_absolute_error(test, y_pred_baseline)
    res['Baseline MAPE'] = mape(test, y_pred_baseline)
    baseline_model = train.iloc[-1]

    # ========== ARIMA ==========
    try:
        arima = ARIMA(train, order=(lags, 0, 0))
        arima_fit = arima.fit()
        y_pred_arima = arima_fit.forecast(steps=len(test))
        res['ARIMA RMSE'] = np.sqrt(mean_squared_error(test, y_pred_arima))
        res['ARIMA MAE']  = mean_absolute_error(test, y_pred_arima)
        res['ARIMA MAPE'] = mape(test, y_pred_arima)
    except Exception as e:
        print(f"ARIMA error for {col}: {e}")
        res['ARIMA RMSE'] = res['ARIMA MAE'] = res['ARIMA MAPE'] = np.nan
        arima_fit = None

    # ========== Prophet ==========
    try:
        df_prophet = pd.DataFrame({'ds': train.index, 'y': train.values})
        prophet_model = Prophet(yearly_seasonality=True, daily_seasonality=False)
        prophet_model.fit(df_prophet)
        future = pd.DataFrame({'ds': test.index})
        y_pred_prophet = prophet_model.predict(future)['yhat'].values
        res['Prophet RMSE'] = np.sqrt(mean_squared_error(test, y_pred_prophet))
        res['Prophet MAE']  = mean_absolute_error(test, y_pred_prophet)
        res['Prophet MAPE'] = mape(test, y_pred_prophet)
    except Exception as e:
        print(f"Prophet error for {col}: {e}")
        res['Prophet RMSE'] = res['Prophet MAE'] = res['Prophet MAPE'] = np.nan
        prophet_model = None

    # ========== XGBoost ==========
    try:
        train_df = pd.DataFrame({'y': train})
        for i in range(1, lags+1):
            train_df[f'lag{i}'] = train.shift(i)
        train_df = train_df.dropna()
        y_xgb = train_df['y']
        X_xgb = train_df.drop('y', axis=1)
        dtrain = xgb.DMatrix(X_xgb.values, label=y_xgb.values)
        bst = xgb.train({"objective": "reg:squarederror"}, dtrain, num_boost_round=100)

        # توقع خطوة بخطوة (walk forward)
        history = train.copy()
        preds_xgb = []
        for t in test.index:
            feat = []
            for i in range(1, lags+1):
                prev_idx = history.index.get_loc(t) - i if t in history.index else len(history)-i
                if prev_idx < 0:
                    feat = []
                    break
                feat.append(history.iloc[prev_idx])
            if len(feat) < lags:
                yhat = history.iloc[-1]
            else:
                arr = np.array(feat).reshape(1, -1)
                dtest = xgb.DMatrix(arr)
                yhat = bst.predict(dtest)[0]
            preds_xgb.append(yhat)
            history.loc[t] = yhat
        y_pred_xgb = np.array(preds_xgb)
        res['XGBoost RMSE'] = np.sqrt(mean_squared_error(test, y_pred_xgb))
        res['XGBoost MAE']  = mean_absolute_error(test, y_pred_xgb)
        res['XGBoost MAPE'] = mape(test, y_pred_xgb)
    except Exception as e:
        print(f"XGBoost error for {col}: {e}")
        res['XGBoost RMSE'] = res['XGBoost MAE'] = res['XGBoost MAPE'] = np.nan
        bst = None

    # ========== LSTM ==========
    try:
        arr = train.values
        X_lstm, y_lstm = [], []
        for i in range(lags, len(arr)):
            X_lstm.append(arr[i-lags:i])
            y_lstm.append(arr[i])
        X_lstm, y_lstm = np.array(X_lstm), np.array(y_lstm)
        X_lstm = X_lstm.reshape((X_lstm.shape[0], X_lstm.shape[1], 1))
        lstm_model = Sequential([
            LSTM(32, activation='relu', input_shape=(lags, 1)),
            Dense(1)
        ])
        lstm_model.compile(optimizer='adam', loss='mse')
        lstm_model.fit(X_lstm, y_lstm, epochs=10, verbose=0)
        last_seq = arr[-lags:]
        preds_lstm = []
        for v in test.values:
            input_seq = last_seq.reshape((1, lags, 1))
            yhat = lstm_model.predict(input_seq, verbose=0)[0][0]
            preds_lstm.append(yhat)
            last_seq = np.append(last_seq[1:], yhat)
        y_pred_lstm = np.array(preds_lstm)
        res['LSTM RMSE'] = np.sqrt(mean_squared_error(test, y_pred_lstm))
        res['LSTM MAE']  = mean_absolute_error(test, y_pred_lstm)
        res['LSTM MAPE'] = mape(test, y_pred_lstm)
    except Exception as e:
        print(f"LSTM error for {col}: {e}")
        res['LSTM RMSE'] = res['LSTM MAE'] = res['LSTM MAPE'] = np.nan
        lstm_model = None

    # ========== اختيار أفضل نموذج ==========
    metric_names = ['Baseline MAPE', 'ARIMA MAPE', 'Prophet MAPE', 'XGBoost MAPE', 'LSTM MAPE']
    mape_scores = [res[m] for m in metric_names]
    best_index = np.nanargmin(mape_scores)
    best_model_name = metric_names[best_index].replace(" MAPE", "")
    res['Best Model'] = best_model_name

    # ========== حفظ النماذج ==========
    currency_clean = clean_filename(col)
    if res['Best Model']== 'Baseline':
        with open(f"models/{currency_clean}_Baseline.txt", "w") as f:
            f.write(str(baseline_model))
    if res['Best Model']== 'ARIMA':
        joblib.dump(arima_fit, f"models/{currency_clean}_ARIMA.pkl")
    if res['Best Model']== 'Prophet':
        joblib.dump(prophet_model, f"models/{currency_clean}_Prophet.pkl")
    if res['Best Model']== 'XGBoost':
        bst.save_model(f"models/{currency_clean}_XGBoost.json")
    if res['Best Model']== 'LSTM':
        lstm_model.save(f"models/{currency_clean}_LSTM.h5")

    results.append(res)

# ========== حفظ النتائج ==========
results_df = pd.DataFrame(results)
print(results_df)
results_df.to_excel("model_comparison.xlsx", index=False)

